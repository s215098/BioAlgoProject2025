{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f79d7ace",
   "metadata": {},
   "source": [
    "# Get binders \n",
    "Script to sort data out and save files only containing binders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845221a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A0101: 103 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A0101/A0101_bind.dat\n",
      "A0201: 1181 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A0201/A0201_bind.dat\n",
      "A0202: 649 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A0202/A0202_bind.dat\n",
      "A0203: 639 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A0203/A0203_bind.dat\n",
      "A0206: 513 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A0206/A0206_bind.dat\n",
      "A0301: 517 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A0301/A0301_bind.dat\n",
      "A1101: 693 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A1101/A1101_bind.dat\n",
      "A2301: 49 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A2301/A2301_bind.dat\n",
      "A2402: 99 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A2402/A2402_bind.dat\n",
      "A2403: 29 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A2403/A2403_bind.dat\n",
      "A2601: 53 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A2601/A2601_bind.dat\n",
      "A2902: 68 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A2902/A2902_bind.dat\n",
      "A3001: 77 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A3001/A3001_bind.dat\n",
      "A3002: 29 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A3002/A3002_bind.dat\n",
      "A3101: 427 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A3101/A3101_bind.dat\n",
      "A3301: 184 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A3301/A3301_bind.dat\n",
      "A6801: 498 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A6801/A6801_bind.dat\n",
      "A6802: 397 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A6802/A6802_bind.dat\n",
      "A6901: 86 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/A6901/A6901_bind.dat\n",
      "B0702: 208 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B0702/B0702_bind.dat\n",
      "B0801: 20 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B0801/B0801_bind.dat\n",
      "B1501: 179 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B1501/B1501_bind.dat\n",
      "B1801: 47 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B1801/B1801_bind.dat\n",
      "B2705: 56 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B2705/B2705_bind.dat\n",
      "B3501: 211 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B3501/B3501_bind.dat\n",
      "B4001: 40 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B4001/B4001_bind.dat\n",
      "B4002: 39 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B4002/B4002_bind.dat\n",
      "B4402: 44 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B4402/B4402_bind.dat\n",
      "B4403: 34 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B4403/B4403_bind.dat\n",
      "B4501: 49 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B4501/B4501_bind.dat\n",
      "B5101: 85 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B5101/B5101_bind.dat\n",
      "B5301: 106 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B5301/B5301_bind.dat\n",
      "B5401: 81 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B5401/B5401_bind.dat\n",
      "B5701: 11 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B5701/B5701_bind.dat\n",
      "B5801: 104 strong binders saved to /Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/B5801/B5801_bind.dat\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List of all HLA alleles\n",
    "hla_list = [\n",
    "    \"A0101\", \"A0201\", \"A0202\", \"A0203\", \"A0206\", \"A0301\", \"A1101\", \"A2301\",\n",
    "    \"A2402\", \"A2403\", \"A2601\", \"A2902\", \"A3001\", \"A3002\", \"A3101\", \"A3301\",\n",
    "    \"A6801\", \"A6802\", \"A6901\", \"B0702\", \"B0801\", \"B1501\", \"B1801\", \"B2705\",\n",
    "    \"B3501\", \"B4001\", \"B4002\", \"B4402\", \"B4403\", \"B4501\", \"B5101\", \"B5301\",\n",
    "    \"B5401\", \"B5701\", \"B5801\"\n",
    "]\n",
    "\n",
    "threshold_nM = 0.426\n",
    "\n",
    "for hla in hla_list:\n",
    "    file_path = f\"/Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/AllFiles/{hla}/{hla}.dat\"\n",
    "    output_path = f\"/Users/mathildedue/Library/CloudStorage/OneDrive-DanmarksTekniskeUniversitet/master_bioinformatics/1.semester/22125_algorithms_in_bioinformatics/BioAlgoProject2025/data/PSSM/{hla}/{hla}_bind.dat\"\n",
    "    bind_count = 0\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        with open(file_path, \"r\") as infile, open(output_path, \"w\") as outfile:\n",
    "            for line in infile:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 3:\n",
    "                    try:\n",
    "                        value = float(parts[1])\n",
    "                        # Saving values that are above the threshold as a value of 1 is the strongest binding\n",
    "                        if value > threshold_nM:\n",
    "                            outfile.write(line)\n",
    "                            bind_count += 1\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "        print(f\"{hla}: {bind_count} strong binders saved to {output_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27acf65a",
   "metadata": {},
   "source": [
    "## Split data into folds (nested 5 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ad1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "Processing HLA: A0201\n",
      "Reading input file: ../data/PSSM/A0201/A0201_bind.dat\n",
      "Parsed 1181 sequences.\n",
      "Label distribution: {0: 1011, 1: 170}\n",
      "\n",
      "Clustering 1181 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 1181 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/A0201/f001.csv\n",
      "    Testing  set -> ../data/PSSM/A0201/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/A0201/f002.csv\n",
      "    Testing  set -> ../data/PSSM/A0201/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/A0201/f003.csv\n",
      "    Testing  set -> ../data/PSSM/A0201/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/A0201/f004.csv\n",
      "    Testing  set -> ../data/PSSM/A0201/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: A0202\n",
      "Reading input file: ../data/PSSM/A0202/A0202_bind.dat\n",
      "Parsed 649 sequences.\n",
      "Label distribution: {0: 543, 1: 106}\n",
      "\n",
      "Clustering 649 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 649 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/A0202/f001.csv\n",
      "    Testing  set -> ../data/PSSM/A0202/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/A0202/f002.csv\n",
      "    Testing  set -> ../data/PSSM/A0202/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/A0202/f003.csv\n",
      "    Testing  set -> ../data/PSSM/A0202/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/A0202/f004.csv\n",
      "    Testing  set -> ../data/PSSM/A0202/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: A1101\n",
      "Reading input file: ../data/PSSM/A1101/A1101_bind.dat\n",
      "Parsed 693 sequences.\n",
      "Label distribution: {0: 580, 1: 113}\n",
      "\n",
      "Clustering 693 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 693 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/A1101/f001.csv\n",
      "    Testing  set -> ../data/PSSM/A1101/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/A1101/f002.csv\n",
      "    Testing  set -> ../data/PSSM/A1101/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/A1101/f003.csv\n",
      "    Testing  set -> ../data/PSSM/A1101/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/A1101/f004.csv\n",
      "    Testing  set -> ../data/PSSM/A1101/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: A3001\n",
      "Reading input file: ../data/PSSM/A3001/A3001_bind.dat\n",
      "Parsed 77 sequences.\n",
      "Label distribution: {0: 67, 1: 10}\n",
      "\n",
      "Clustering 77 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 77 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/A3001/f001.csv\n",
      "    Testing  set -> ../data/PSSM/A3001/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/A3001/f002.csv\n",
      "    Testing  set -> ../data/PSSM/A3001/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/A3001/f003.csv\n",
      "    Testing  set -> ../data/PSSM/A3001/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/A3001/f004.csv\n",
      "    Testing  set -> ../data/PSSM/A3001/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: B0702\n",
      "Reading input file: ../data/PSSM/B0702/B0702_bind.dat\n",
      "Parsed 208 sequences.\n",
      "Label distribution: {0: 172, 1: 36}\n",
      "\n",
      "Clustering 208 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 208 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/B0702/f001.csv\n",
      "    Testing  set -> ../data/PSSM/B0702/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/B0702/f002.csv\n",
      "    Testing  set -> ../data/PSSM/B0702/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/B0702/f003.csv\n",
      "    Testing  set -> ../data/PSSM/B0702/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/B0702/f004.csv\n",
      "    Testing  set -> ../data/PSSM/B0702/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: B1501\n",
      "Reading input file: ../data/PSSM/B1501/B1501_bind.dat\n",
      "Parsed 179 sequences.\n",
      "Label distribution: {0: 107, 1: 72}\n",
      "\n",
      "Clustering 179 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 179 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/B1501/f001.csv\n",
      "    Testing  set -> ../data/PSSM/B1501/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/B1501/f002.csv\n",
      "    Testing  set -> ../data/PSSM/B1501/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/B1501/f003.csv\n",
      "    Testing  set -> ../data/PSSM/B1501/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/B1501/f004.csv\n",
      "    Testing  set -> ../data/PSSM/B1501/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: B5401\n",
      "Reading input file: ../data/PSSM/B5401/B5401_bind.dat\n",
      "Parsed 81 sequences.\n",
      "Label distribution: {0: 68, 1: 13}\n",
      "\n",
      "Clustering 81 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 81 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/B5401/f001.csv\n",
      "    Testing  set -> ../data/PSSM/B5401/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/B5401/f002.csv\n",
      "    Testing  set -> ../data/PSSM/B5401/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/B5401/f003.csv\n",
      "    Testing  set -> ../data/PSSM/B5401/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/B5401/f004.csv\n",
      "    Testing  set -> ../data/PSSM/B5401/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n",
      "============================\n",
      "Processing HLA: B5701\n",
      "Reading input file: ../data/PSSM/B5701/B5701_bind.dat\n",
      "Parsed 11 sequences.\n",
      "Label distribution: {0: 7, 1: 4}\n",
      "\n",
      "Clustering 11 sequences using Hobohm 1 (identity cutoff = 0.9)...\n",
      "Identified 11 unique clusters.\n",
      "\n",
      "Creating nested 5-fold cross-validation splits...\n",
      "\n",
      "  Inner fold 1:\n",
      "    Training set -> ../data/PSSM/B5701/f001.csv\n",
      "    Testing  set -> ../data/PSSM/B5701/c001.csv\n",
      "  Inner fold 2:\n",
      "    Training set -> ../data/PSSM/B5701/f002.csv\n",
      "    Testing  set -> ../data/PSSM/B5701/c002.csv\n",
      "  Inner fold 3:\n",
      "    Training set -> ../data/PSSM/B5701/f003.csv\n",
      "    Testing  set -> ../data/PSSM/B5701/c003.csv\n",
      "  Inner fold 4:\n",
      "    Training set -> ../data/PSSM/B5701/f004.csv\n",
      "    Testing  set -> ../data/PSSM/B5701/c004.csv\n",
      "Done with outer fold 1 (only one generated).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# ------------------------\n",
    "# Hobohm 1 Clustering\n",
    "# ------------------------\n",
    "def simple_seq_identity(a: str, b: str) -> float:\n",
    "    dp = np.zeros((len(a)+1, len(b)+1), dtype=int)\n",
    "    for i in range(len(a)+1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(len(b)+1):\n",
    "        dp[0][j] = j\n",
    "    for i in range(1, len(a)+1):\n",
    "        for j in range(1, len(b)+1):\n",
    "            cost = 0 if a[i-1] == b[j-1] else 1\n",
    "            dp[i][j] = min(dp[i-1][j] + 1, dp[i][j-1] + 1, dp[i-1][j-1] + cost)\n",
    "    edit_distance = dp[len(a)][len(b)]\n",
    "    return 1 - edit_distance / max(len(a), len(b))\n",
    "\n",
    "def hobohm1(seqs: List[str], cutoff: float = 0.3) -> np.ndarray:\n",
    "    print(f\"Clustering {len(seqs)} sequences using Hobohm 1 (identity cutoff = {cutoff})...\")\n",
    "    order = np.argsort([-len(s) for s in seqs])\n",
    "    reps, clusters = [], np.full(len(seqs), -1, int)\n",
    "    for idx in order:\n",
    "        s = seqs[idx]\n",
    "        for rep_id in reps:\n",
    "            if simple_seq_identity(s, seqs[rep_id]) >= cutoff:\n",
    "                clusters[idx] = clusters[rep_id]\n",
    "                break\n",
    "        else:\n",
    "            clusters[idx] = len(reps)\n",
    "            reps.append(idx)\n",
    "    print(f\"Identified {len(reps)} unique clusters.\\n\")\n",
    "    return clusters\n",
    "\n",
    "# ------------------------\n",
    "# Nested CV Processing for One File\n",
    "# ------------------------\n",
    "def process_peptide_file(input_path: str, output_dir: str, cutoff: float = 0.9):\n",
    "    print(f\"Reading input file: {input_path}\")\n",
    "    if not os.path.exists(input_path):\n",
    "        print(f\"  File not found: {input_path}\\n\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(input_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    sequences = []\n",
    "    affinities = []\n",
    "    alleles = []\n",
    "\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        seq, affinity_str, allele = parts\n",
    "        sequences.append(seq)\n",
    "        affinities.append(float(affinity_str))\n",
    "        alleles.append(allele)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"sequence\": sequences,\n",
    "        \"affinity\": affinities,\n",
    "        \"allele\": alleles\n",
    "    })\n",
    "    df[\"label\"] = df[\"affinity\"].apply(lambda x: 1 if x < 0.5 else 0)\n",
    "\n",
    "    print(f\"Parsed {len(df)} sequences.\")\n",
    "    print(f\"Label distribution: {df['label'].value_counts().to_dict()}\\n\")\n",
    "\n",
    "    groups = hobohm1(df[\"sequence\"].tolist(), cutoff=cutoff)\n",
    "\n",
    "    outer_cv = GroupKFold(n_splits=5)\n",
    "    print(\"Creating nested 5-fold cross-validation splits...\\n\")\n",
    "\n",
    "    def save_formatted(df_part, path):\n",
    "        # Format affinity with 6 decimal places and write\n",
    "        df_out = df_part[[\"sequence\", \"affinity\", \"allele\"]].copy()\n",
    "        df_out[\"affinity\"] = df_out[\"affinity\"].map(lambda x: f\"{x:.6f}\")\n",
    "        df_out.to_csv(path, sep=\" \", index=False, header=False)\n",
    "\n",
    "    for outer_idx, (train_val_idx, eval_idx) in enumerate(outer_cv.split(df[\"sequence\"], df[\"label\"], groups)):\n",
    "        save_formatted(df.iloc[eval_idx], os.path.join(output_dir, \"e000\"))\n",
    "\n",
    "        train_val_df = df.iloc[train_val_idx]\n",
    "        inner_groups = groups[train_val_idx]\n",
    "        inner_cv = GroupKFold(n_splits=4)\n",
    "\n",
    "        for inner_idx, (train_idx, test_idx) in enumerate(inner_cv.split(train_val_df[\"sequence\"], train_val_df[\"label\"], inner_groups)):\n",
    "            f_file = os.path.join(output_dir, f\"f00{inner_idx+1}\")\n",
    "            c_file = os.path.join(output_dir, f\"c00{inner_idx+1}\")\n",
    "\n",
    "            save_formatted(train_val_df.iloc[train_idx], f_file)\n",
    "            save_formatted(train_val_df.iloc[test_idx], c_file)\n",
    "\n",
    "            print(f\"  Inner fold {inner_idx+1}:\")\n",
    "            print(f\"    Training set -> {f_file}\")\n",
    "            print(f\"    Testing  set -> {c_file}\")\n",
    "\n",
    "        print(\"Done with outer fold 1 (only one generated).\\n\")\n",
    "        break\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# Batch Processing for All HLA Alleles\n",
    "# ------------------------\n",
    "hla_list = [\n",
    "    \"A0201\", \"A0202\", \"A1101\", \"A3001\", \n",
    "    \"B0702\", \"B1501\", \"B5401\", \"B5701\"\n",
    "]\n",
    "\n",
    "base_input_dir = f\"../data/all_files_new/\"         # Directory where .dat files are located\n",
    "base_output_dir = \"../data/all_files_new/\"   # Output directory for CV files\n",
    "cutoff = 0.9                 # Sequence identity cutoff for clustering\n",
    "\n",
    "# Ensure top-level output directory exists\n",
    "os.makedirs(base_output_dir, exist_ok=True)\n",
    "\n",
    "for hla in hla_list:\n",
    "    input_file = os.path.join(base_input_dir, f\"{hla}/{hla}_bind.dat\")\n",
    "    output_path = os.path.join(base_output_dir, hla)\n",
    "    print(\"============================\")\n",
    "    print(f\"Processing HLA: {hla}\")\n",
    "    process_peptide_file(input_file, output_path, cutoff=cutoff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
