{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define runtime parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define if we are using blosum or sparse encoding\n",
    "blosum_scheme = False\n",
    "#blosum_scheme = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_file = data_dir + \"Matrices/alphabet\"\n",
    "#alphabet_file = \"https://raw.githubusercontent.com/brunoalvarez89/data/master/algorithms_in_bioinformatics/part_3/alphabet\"\n",
    "alphabet = np.loadtxt(alphabet_file, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blosu50 encoding scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blosum_file = data_dir + \"Matrices/blosum50\"\n",
    "#blosum_file = \"https://raw.githubusercontent.com/brunoalvarez89/data/master/algorithms_in_bioinformatics/part_3/blosum50\"\n",
    "\n",
    "_blosum50 = np.loadtxt(blosum_file, dtype=float).reshape((24, -1)).T\n",
    "\n",
    "blosum50 = {}\n",
    "\n",
    "for i, letter_1 in enumerate(alphabet):\n",
    "    \n",
    "    blosum50[letter_1] = {}\n",
    "\n",
    "    for j, letter_2 in enumerate(alphabet):\n",
    "        \n",
    "        blosum50[letter_1][letter_2] = _blosum50[i, j] / 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparce encoding scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_file = data_dir + \"Matrices/sparse\"\n",
    "\n",
    "_sparse = np.loadtxt(sparse_file, dtype=float)\n",
    "sparse = {}\n",
    "\n",
    "for i, letter_1 in enumerate(alphabet):\n",
    "\n",
    "    sparse[letter_1] = {}\n",
    "\n",
    "    for j, letter_2 in enumerate(alphabet):\n",
    "\n",
    "        sparse[letter_1][letter_2] = _sparse[i, j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peptide encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(peptides, encoding_scheme, alphabet):\n",
    "    \"\"\"\n",
    "    Encode a list of peptides using the specified encoding scheme.\n",
    "\n",
    "        Parameters:\n",
    "            peptides (list): List of peptide sequences to encode.\n",
    "            encoding_scheme (dict): Dictionary containing the encoding scheme.\n",
    "            alphabet (list): List of letters in the alphabet used for encoding.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: A 2D numpy array where each row corresponds to an encoded peptide.\n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_peptides = []\n",
    "\n",
    "    for peptide in peptides:\n",
    "\n",
    "        encoded_peptide = []\n",
    "\n",
    "        for peptide_letter in peptide:\n",
    "\n",
    "            for alphabet_letter in alphabet:\n",
    "\n",
    "                encoded_peptide.append(encoding_scheme[peptide_letter][alphabet_letter])\n",
    "        \n",
    "        # add a 1 (bias)\n",
    "        encoded_peptide.append(1)\n",
    "        \n",
    "        # store peptide\n",
    "        encoded_peptides.append(encoded_peptide)\n",
    "        \n",
    "    return np.array(encoded_peptides)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation (sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid function for a given input.\n",
    "\n",
    "        Parameters:\n",
    "            z (float or np.ndarray): Input value(s) for which to compute the sigmoid.\n",
    "\n",
    "        Returns:\n",
    "            float or np.ndarray: The computed sigmoid value(s).\n",
    "    \"\"\"    \n",
    "    \n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, w1, w2):\n",
    "    \n",
    "    # X contains the output from each layer, i.e the input values in the first layer\n",
    "    # w1 are weights connecting input to hidden, and w2 weights connecting hidden to output\n",
    "    # In w[i,j]; i is from and j is to\n",
    "   \n",
    "    # get dimension, substracting the bias\n",
    "    input_layer_dim = w1.shape[0] - 1 \n",
    "    hidden_layer_dim = w2.shape[0] - 1\n",
    "    \n",
    "    ################\n",
    "    # hidden layer #\n",
    "    ################\n",
    "    \n",
    "    # activity of hidden layer\n",
    "    # Remember z_j = sum_i w(i,j)*input(i)\n",
    "    for j in range(hidden_layer_dim):\n",
    "        z = 0.0\n",
    "        for i in range(input_layer_dim+1):\n",
    "            # z += XXX\n",
    "            z += X[0][i] * w1[i, j] # This is the first layer, so we use X[0]. w1 connects input to hidden, so we use w1[i][j] because we have j neurons in the hidden layer.\n",
    "        # X[1][j] = XXX\n",
    "        X[1][j] = sigmoid(z) # This is the second layer, so we use X[1]\n",
    "    \n",
    "    ################\n",
    "    # output layer #\n",
    "    ################\n",
    "    \n",
    "    z = 0\n",
    "    for i in range(hidden_layer_dim+1):\n",
    "        # z += XXX\n",
    "        z += X[1][i] * w2[i, 0] # This is the second layer, so we use X[1]. w2 connects hidden to output, so we use w2[i][0] because we have only one output neuron.\n",
    "    # X[2][0] = XXX\n",
    "    X[2][0] = sigmoid(z) # This is the third layer, so we use X[2]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_file = data_dir + \"ANN/A2403_evaluation\"     # Should be changed!!!\n",
    "\n",
    "evaluation_data = np.loadtxt(evaluation_file, dtype=str)\n",
    "\n",
    "peptides = evaluation_data[:, 0]\n",
    "if blosum_scheme:\n",
    "    x_eval = encode(peptides, blosum50, alphabet)\n",
    "else:\n",
    "    x_eval = encode(peptides, sparse, alphabet)\n",
    "\n",
    "y_eval = np.array(evaluation_data[:, 1], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load previously saved Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network(file_name):\n",
    "    \"\"\"\n",
    "    Load the weights of a neural network from a file.\n",
    "        \n",
    "        Parameters:\n",
    "            file_name (str): The name of the file containing the network weights.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing two numpy arrays:\n",
    "                - w_h_load: Weights from input layer to hidden layer.\n",
    "                - w_o_load: Weights from hidden layer to output layer.\n",
    "    \"\"\"\n",
    "\n",
    "    f = open(file_name, \"r\")\n",
    "\n",
    "    n_line = 0\n",
    "\n",
    "    weight_list = []\n",
    "\n",
    "    for line in f:\n",
    "\n",
    "\n",
    "        # clean and separate line\n",
    "        sline = line.strip().split()\n",
    "\n",
    "\n",
    "        # input layer dimension\n",
    "        if n_line == 1:\n",
    "            input_layer_dim = int(sline[0])\n",
    "\n",
    "        # hidden layer dimension    \n",
    "        if n_line == 2:\n",
    "            hidden_layer_dim = int(sline[0])\n",
    "\n",
    "        # output layer dimension\n",
    "        if n_line == 3:\n",
    "            output_layer_dim = int(sline[0])\n",
    "\n",
    "        # model weights\n",
    "        if n_line >= 5:\n",
    "            for i in range(0, len(sline)):\n",
    "                weight_list.append(float(sline[i]))\n",
    "\n",
    "        n_line += 1\n",
    "\n",
    "    # HIDDEN LAYER WEIGHTS\n",
    "    # w_h[i, j] is the weight that links input's feature \"i\" to neuron \"j\" of the hidden layer        \n",
    "    w_h_load = np.zeros(shape=(input_layer_dim+1, hidden_layer_dim))\n",
    "\n",
    "    for i in range(0, (input_layer_dim+1)*hidden_layer_dim, hidden_layer_dim):\n",
    "\n",
    "        for j in range(0, hidden_layer_dim):\n",
    "\n",
    "            row = i // hidden_layer_dim\n",
    "\n",
    "            w_h_load[row, j] = weight_list[i+j]\n",
    "\n",
    "            \n",
    "    # OUTPUT LAYER WEIGHTS\n",
    "    # w_o[i, j] is the weight that links hidden layer's neuron \"i\" to neuron \"j\" of the output layer\n",
    "    w_o_load = np.zeros(shape=(hidden_layer_dim+1, output_layer_dim))\n",
    "\n",
    "    w_h_end = (input_layer_dim+1) * hidden_layer_dim\n",
    "\n",
    "    for i in range(w_h_end, w_h_end+hidden_layer_dim+1, output_layer_dim):\n",
    "\n",
    "        for j in range(0, output_layer_dim):\n",
    "\n",
    "            row = (i - w_h_end) // output_layer_dim\n",
    "            w_o_load[row, j] = weight_list[i+j]\n",
    "            \n",
    "            \n",
    "    # return weight matrices\n",
    "    return w_h_load, w_o_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network\n",
    "synfile_name = data_dir + \"ANN/A2403_sp.syn\"\n",
    "# synfile_name = data_dir + \"ANN/A2403_bl.syn\"\n",
    "# synfile_name = data_dir + \"ANN/A0201_sp.syn\"\n",
    "# synfile_name = data_dir + \"ANN/A0201_bl.syn\"\n",
    "w_h, w_o = load_network(synfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X matrix \n",
    "input_layer_dim = w_h.shape[0]\n",
    "hidden_layer_dim = w_o.shape[0]\n",
    "output_layer_dim = w_o.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max network dimensions\n",
    "X_dim = max(input_layer_dim, hidden_layer_dim, output_layer_dim)\n",
    "X = np.zeros(shape=(3, X_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last column in each X layer is set to 1 to deal with the bias weights\n",
    "X[0][input_layer_dim-1] = 1.0 \n",
    "X[1][hidden_layer_dim-1] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for plotting\n",
    "y_preds_eval = []\n",
    "\n",
    "# loop\n",
    "for i in range(0, len(x_eval)):        \n",
    "\n",
    "    # fetch training point\n",
    "    x = x_eval[i]\n",
    "    y = y_eval[i]\n",
    "\n",
    "    if len(x) == input_layer_dim:\n",
    "        \n",
    "        X[0] = x\n",
    "\n",
    "        # forward propagation\n",
    "        forward(X, w_h, w_o)\n",
    "        # y_pred = XXX\n",
    "        y_pred = X[2][0] # This is the third layer, so we use X[2][0] to get the output prediction\n",
    "        \n",
    "        y_preds_eval.append(y_pred)\n",
    "        \n",
    "        print(peptides[i], y, y_pred)\n",
    "    else:\n",
    "        print(\"Error. Peptide length\", len(x),\"does not match network sizs\", input_layer_dim, \"Skip\")\n",
    "\n",
    "# store training performance\n",
    "eval_perf = pearsonr(y_eval, np.asarray(y_preds_eval))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORMANCE REPORT\n",
    "fig = plt.figure(figsize=(5, 5), dpi = 70)\n",
    "\n",
    "plt.scatter(y_preds_eval, y_eval)\n",
    "plt.ylabel(\"Target Value\", fontsize=10);\n",
    "plt.xlabel(\"Prediction Value\", fontsize=10);\n",
    "\n",
    "# print performance\n",
    "print(\"# Prediction PCC:\", round(eval_perf, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
